{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import gradio as gr\n",
    "\n",
    "from dataclasses import asdict, dataclass\n",
    "from textwrap import dedent\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from huggingface_hub import login\n",
    "from transformers import pipeline\n",
    "from diffusers.pipelines.flux.pipeline_flux import FluxPipeline\n",
    "from diffusers import DiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "\n",
    "# initialize key components\n",
    "# task = kwargs.get(\"task\", \"text-to-image\")\n",
    "# model_id = kwargs.get(\"model_id\", \"black-forest-labs/FLUX.1-dev\")\n",
    "# world_size = kwargs.get(\"world_size\", 1)\n",
    "# rank = kwargs.get(\"rank\", 0)\n",
    "# master_add = kwargs.get(\"master_add\", \"127.0.0.1\")\n",
    "# master_port = kwargs.get(\"master_port\", \"12345\")\n",
    "# project_id = project\n",
    "\n",
    "task = \"text-to-image\"\n",
    "base_model_id = \"black-forest-labs/FLUX.1-dev\"\n",
    "\n",
    "css = \"\"\"\n",
    "    .importantButton {\n",
    "        background: linear-gradient(45deg, #7e0570,#5d1c99, #6e00ff) !important;\n",
    "        border: none !important;\n",
    "    }\n",
    "    .importantButton:hover {\n",
    "        background: linear-gradient(45deg, #ff00e0,#8500ff, #6e00ff) !important;\n",
    "        border: none !important;\n",
    "    }\n",
    "    .disclaimer {font-variant-caps: all-small-caps; font-size: xx-small;}\n",
    "    .xsmall {font-size: x-small;}\n",
    "\"\"\"\n",
    "\n",
    "example_list = [\n",
    "    \"A cat balancing on a pole\",\n",
    "    \"2 cats fighting each other\",\n",
    "    \"A big river flowing near a mountain\",\n",
    "    \"Red hair girl, anime style\",\n",
    "    \"Black hair girl, oil painting\",\n",
    "    \"She sells seashell by the seashore\"\n",
    "]\n",
    "\n",
    "model_list = {\n",
    "    \"FLUX.1-dev\": \"black-forest-labs/FLUX.1-dev\",\n",
    "    \"FLUX.1-schnell\": \"black-forest-labs/FLUX.1-schnell\",\n",
    "    \"Flux-Super-Realism-LoRA\": \"strangerzonehf/Flux-Super-Realism-LoRA\"\n",
    "}\n",
    "\n",
    "\n",
    "# print(f'''\\\n",
    "# Project ID: {project_id}\n",
    "# Label config: {self.label_config}\n",
    "# Parsed JSON Label config: {self.parsed_label_config}''')\n",
    "hf_access_token = \"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\"\n",
    "# hf_access_token = kwargs.get(\"hf_access_token\", \"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\")\n",
    "login(token=hf_access_token)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gpu(s)\n",
    "n_gpus = torch.cuda.device_count()\n",
    "try:\n",
    "    _ = f\"{int(torch.cuda.mem_get_info()[0] / 1024 ** 3) - 2}GB\"\n",
    "except AssertionError:\n",
    "    _ = 0\n",
    "max_memory = {i: _ for i in range(n_gpus)}\n",
    "print('max memory:', max_memory)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "  guidance_scale = 3.0\n",
    "  step = 1\n",
    "  width = 64\n",
    "  height = 64\n",
    "  prompt = \"\"\n",
    "\n",
    "STATS_DEFAULT = SimpleNamespace(llm=None, config=Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handler\n",
    "\n",
    "# button to generate image from input text\n",
    "def generate_btn_handler(model: str, prompt: str, guidance_scale: float, step: int, width: int,\n",
    "                          height: int) -> tuple:\n",
    "    if prompt == \"\" or prompt is None:\n",
    "        return None, \"\"\n",
    "\n",
    "    # model = model_list[model]\n",
    "\n",
    "    compute_capability = torch.cuda.get_device_properties(0).major\n",
    "    if compute_capability > 8:\n",
    "        torch_dtype = torch.bfloat16\n",
    "    elif compute_capability>7:\n",
    "        torch_dtype = torch.float16\n",
    "    else:\n",
    "        torch_dtype = None  # auto setup for < 7\n",
    "    \n",
    "    try:\n",
    "        pipe = FluxPipeline.from_pretrained(model, torch_dtype=torch_dtype)\n",
    "    except Exception as e:\n",
    "        base_model = base_model_id\n",
    "        pipe = DiffusionPipeline.from_pretrained(base_model, torch_dtype=torch_dtype)\n",
    "        pipe.load_lora_weights(model)\n",
    "\n",
    "    # # for low GPU RAM, quantize from 16b to 8b\n",
    "    # quantize(pipe.transformer, weights=qfloat8)\n",
    "    # freeze(pipe.transformer)\n",
    "    # quantize(pipe.text_encoder_2, weights=qfloat8)\n",
    "    # freeze(pipe.text_encoder_2)\n",
    "\n",
    "    # # for even lower GPU RAM\n",
    "    # pipe.vae.enable_tiling()\n",
    "    # pipe.vae.enable_slicing()\n",
    "\n",
    "    pipe.enable_sequential_cpu_offload()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        num_inference_steps=step,\n",
    "        guidance_scale=guidance_scale,\n",
    "        generator=torch.Generator(device=device)\n",
    "    ).images[0]\n",
    "\n",
    "    pipe = None\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return image, \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradio ui\n",
    "\n",
    "with gr.Blocks(\n",
    "        theme=gr.themes.Soft(text_size=\"sm\"),\n",
    "        title=\"Flux Image Generator\",\n",
    "        css=css, ) as demo_txt_to_img:\n",
    "\n",
    "    stats = gr.State(STATS_DEFAULT)\n",
    "    config = asdict(stats.value.config)\n",
    "\n",
    "    with gr.Row():\n",
    "        # model = gr.Dropdown(list(model_list.keys()), label=\"Select VLLM Model\", type=\"value\")\n",
    "        model = gr.Textbox(value=base_model_id, label=\"Select VLLM Model from Huggingface/local repo\", type=\"text\", interactive=True, )\n",
    "    with gr.Row():\n",
    "        image_field = gr.Image(label=\"Output Image\", elem_id=\"output_image\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            prompt = gr.TextArea(label=\"Prompt:\", elem_id=\"small-textarea\", lines=10, max_lines=8)\n",
    "            generate_btn = gr.Button(\"Generate\")\n",
    "        with gr.Column(scale=1):\n",
    "            guidance_scale = gr.Slider(value=STATS_DEFAULT.config.guidance_scale, minimum=0.0, maximum=30.0,\n",
    "                                        step=0.1, label=\"Guidance scale\")\n",
    "            step = gr.Slider(value=STATS_DEFAULT.config.step, minimum=1, maximum=100, step=1, label=\"Step\")\n",
    "            width = gr.Number(value=STATS_DEFAULT.config.width, label='Image width (64-1024)', precision=0,\n",
    "                              minimum=64, maximum=1024, interactive=True)\n",
    "            height = gr.Number(value=STATS_DEFAULT.config.width, label='Image height (64-1024)', precision=0,\n",
    "                                minimum=64, maximum=1024, interactive=True)\n",
    "\n",
    "    with gr.Accordion(\"Example inputs\", open=True):\n",
    "        examples = gr.Examples(\n",
    "            examples=example_list,\n",
    "            inputs=[prompt],\n",
    "            examples_per_page=60,\n",
    "        )\n",
    "\n",
    "    # Event handlers\n",
    "    generate_btn.click(fn=generate_btn_handler,\n",
    "                        inputs=[model, prompt, guidance_scale, step, width, height],\n",
    "                        outputs=[image_field, prompt],\n",
    "                        api_name=\"generate\")\n",
    "\n",
    "with gr.Blocks(css=\"style.css\") as demo:\n",
    "    gr.Markdown(\"Flux VLLM\")\n",
    "    with gr.Tabs():\n",
    "        if task == \"text-to-image\":\n",
    "            with gr.Tab(label=task):\n",
    "                demo_txt_to_img.render()\n",
    "        # else:\n",
    "            # return {\"share_url\": \"\", 'local_url': \"\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch gradio app\n",
    "gradio_app, local_url, share_url = demo.launch(share=True, quiet=True, prevent_thread_lock=True,\n",
    "                                                server_name='0.0.0.0', show_error=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
